{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Iris dataset\n",
    "\n",
    "Also included in scikit-learn is the well-known Iris dataset.\n",
    "\n",
    "## Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the usual imports\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are botanical features ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... for 3 species of Iris flower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for better inspection, we build a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a DataFrame with column names = iris.feature_names and a \"target\" column containing the class labels\n",
    "### fill in missing code\n",
    "df = \n",
    "df['target'] = \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the intercorrelations of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[iris.feature_names].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure()\n",
    "coefs = np.corrcoef(df[iris.feature_names].values.T)\n",
    "sns.set(style='whitegrid')\n",
    "hm = sns.heatmap(coefs, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=df[iris.feature_names].columns, xticklabels=df[iris.feature_names].columns) \n",
    "plt.show()\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the predictors are very much correlated. For classification, we will choose just two features, namely the uncorrelated sepal_width and sepal_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### fill in missing code\n",
    "# just use features 0 and 1\n",
    "X = X[:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Normally we would split the data into training and test sets. In this case, as we don't have enough data to meaningfully do that, we will use cross validation to average over iteratively performed train-test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let's first use logistic regression on the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "skf = StratifiedKFold(y = y, n_folds = 10)\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    ### fill in missing code\n",
    "    logistic_model = \n",
    "    \n",
    "    accuracies_train.append(logistic_model.score(X_train, y_train))\n",
    "    # same for test\n",
    "    ### fill in missing code\n",
    "    accuracies_test.append\n",
    "\n",
    "print 'training accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_train))\n",
    "print 'average training accuracy: {}\\n'.format(round(np.mean(accuracies_train),2))\n",
    "print 'test accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_test))\n",
    "print 'average test accuracy: {}\\n'.format(round(np.mean(accuracies_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the predictions from the last of these models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at model predictions\n",
    "### fill in missing code\n",
    "y_predicted = \n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from https://github.com/rasbt/python-machine-learning-book\n",
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_regions(title, X, y, classifier, resolution=0.02):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('cyan', 'red', 'orange', 'gray', 'blue')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)\n",
    "\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the decision boundaries of the logistic regression model (again, looking at the last one from above, as they behaved very similarly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_regions('Decision regions', X, y, logistic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that one class is correctly identified in general, while the other two are not linearly separable. \n",
    "We can confirm this by looking at the confusion matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y, logistic_model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Next, let's try a nonlinear classifier: a support vector machine (with the scikit-learn default RBF kernel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "skf = StratifiedKFold(y = y, n_folds = 10)\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    ### fill in missing code\n",
    "    svc_model = \n",
    "    \n",
    "    accuracies_train.append(svc_model.score(X_train, y_train))\n",
    "    ### fill in missing code\n",
    "    # same for test\n",
    "    accuracies_test.append\n",
    "\n",
    "print 'training accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_train))\n",
    "print 'average training accuracy: {}\\n'.format(round(np.mean(accuracies_train),2))\n",
    "print 'test accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_test))\n",
    "print 'average test accuracy: {}\\n'.format(round(np.mean(accuracies_test),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see SVM performs better than logistic regression on both test and training sets.\n",
    "How do its decision boundaries look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_regions('Decision regions', X, y, svc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### fill in missing code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "Next, try another nonlinear classifier, decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "skf = StratifiedKFold(y = y, n_folds = 10)\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    ### fill in missing code\n",
    "    tree_model = \n",
    "    \n",
    "    accuracies_train.append(tree_model.score(X_train, y_train))\n",
    "    ### fill in missing code\n",
    "    # same for test\n",
    "    accuracies_test.append(tree_model.score(X_test, y_test))\n",
    "\n",
    "print 'training accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_train))\n",
    "print 'average training accuracy: {}\\n'.format(round(np.mean(accuracies_train),2))\n",
    "print 'test accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_test))\n",
    "print 'average test accuracy: {}\\n'.format(round(np.mean(accuracies_test),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on test set is much lower than on training set. The tree is clearly overfitted.\n",
    "We can confirm this looking at the decision boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_regions('Decision regions', X, y, tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many nodes the tree has (for 150 data points!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_model.tree_.node_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - constrained\n",
    "\n",
    "We now build another tree, restricted to having not fewer than 5 samples at every leaf.\n",
    "How does it perform, and how do the decision boundaries look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(y = y, n_folds = 10)\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    ### fill in missing code\n",
    "    tree_model = \n",
    "    \n",
    "    accuracies_train.append(tree_model.score(X_train, y_train))\n",
    "    ### fill in missing code\n",
    "    # same for test\n",
    "    accuracies_test.append(tree_model.score(X_test, y_test))\n",
    "\n",
    "print 'training accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_train))\n",
    "print 'average training accuracy: {}\\n'.format(round(np.mean(accuracies_train),2))\n",
    "print 'test accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_test))\n",
    "print 'average test accuracy: {}\\n'.format(round(np.mean(accuracies_test),2))\n",
    "\n",
    "plot_decision_regions('Decision regions', X, y, tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Tree\n",
    "\n",
    "Finally, let's try boosting, using scikit-learn's GradientBoostingClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "skf = StratifiedKFold(y = y, n_folds = 10)\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    gb_model = ensemble.GradientBoostingClassifier(n_estimators=200)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    accuracies_train.append(gb_model.score(X_train, y_train))\n",
    "    accuracies_test.append(gb_model.score(X_test, y_test))\n",
    "\n",
    "print 'training accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_train))\n",
    "print 'average training accuracy: {}\\n'.format(round(np.mean(accuracies_train),2))\n",
    "print 'test accuracies: {}\\n'.format(map(lambda x: round(x,2), accuracies_test))\n",
    "print 'average test accuracy: {}\\n'.format(round(np.mean(accuracies_test),2))\n",
    "\n",
    "plot_decision_regions('Decision regions', X, y, gb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the ensemble looks overfitted, but test error is not as bad as in the case of the unconstrained decision tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
